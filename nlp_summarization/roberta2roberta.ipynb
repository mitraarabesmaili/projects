{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbf4fe2-684c-4f7d-be3e-7303049734d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:18:53.014910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 09:18:53.015141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 09:18:53.565574: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 09:18:54.896914: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 09:19:01.998930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from datasets import ClassLabel\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments,AutoTokenizer,RobertaConfig\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import BertTokenizer\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55f75377-5ae2-46c6-9149-85bc772cc4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4624217ab9417db38badeff1a93432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pn_summary.py:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dabbf3f53f48c9a03861a6acc5dfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f082a4c8412842009a0ef7dfdf582e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pn_summary.zip:   0%|          | 0.00/89.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b57c6eee1104b0a81fd2f2077a057db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/82022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a28a535e2194202ad02dcb482bb8215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620197d7c4cf4ab2ba8c8d9aec079a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = datasets.load_dataset(\n",
    "    \"pn_summary\", split=\"train\", download_mode=\"force_redownload\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59be6124-b460-45c9-9824-df7ede4cdcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/roberta-fa-zwnj-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8dd28c5-315b-4e81-b1b4-4756c4c2cb15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    for i in range(len(batch['article'])):\n",
    "      batch['article'][i]=normalizer.normalize(batch['article'][i])\n",
    "      batch['summary'][i]=normalizer.normalize(batch['summary'][i])\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch[\"article\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"summary\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=decoder_max_length,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "\n",
    "    # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`.\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [0 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "653911ae-f330-4c6f-96a0-d77b4ea0b8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = Rouge()\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "\n",
    "    labels = np.where(labels != 0, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Compute ROUGE scores\n",
    "    result = metric.get_scores(decoded_preds, decoded_labels,avg=True)\n",
    "    print(result)\n",
    "    with open(\"result_roberta2roberta_temp.txt\",\"a\") as handler:\n",
    "        handler.write(f'rouge-1 - recall: {result[\"rouge-1\"][\"r\"]} - precision: {result[\"rouge-1\"][\"p\"]} - fscore: {result[\"rouge-1\"][\"f\"]}\\n')\n",
    "        handler.write(f'rouge-2 - recall: {result[\"rouge-2\"][\"r\"]} - precision: {result[\"rouge-2\"][\"p\"]} - fscore: {result[\"rouge-2\"][\"f\"]}\\n')\n",
    "        handler.write(f'rouge-l - recall: {result[\"rouge-l\"][\"r\"]} - precision: {result[\"rouge-l\"][\"p\"]} - fscore: {result[\"rouge-l\"][\"f\"]}\\n\\n')\n",
    "    # Extract F-measure for each ROUGE score\n",
    "    rouge_result = {\n",
    "        \"rouge1\": result[\"rouge-1\"][\"f\"],\n",
    "        \"rouge2\": result[\"rouge-2\"][\"f\"],\n",
    "        \"rougeL\": result[\"rouge-l\"][\"f\"],\n",
    "    }\n",
    "\n",
    "    return rouge_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74aa7ff1-7cc4-4117-867a-b6faf647e05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "encoder_max_length = 512\n",
    "decoder_max_length = 128\n",
    "#train_data = train_data.select(range(10000))\n",
    "# batch_size = 16\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e7637-ab35-4c11-8b13-73f382330e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.map(\n",
    "        process_data_to_model_inputs,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        remove_columns=['id', 'title', 'article', 'summary', 'category', 'categories', 'network', 'link'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815af5f-7dcb-4d83-8280-7329bd075612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d1d5-0fe2-4758-b0bb-9b6500a3494d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = datasets.load_dataset(\n",
    "        \"pn_summary\", split=\"validation\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd780e-729a-4a5a-9276-aa1474a36163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = val_data.map(\n",
    "        process_data_to_model_inputs,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        remove_columns=['id', 'title', 'article', 'summary', 'category', 'categories', 'network', 'link'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef9cec-faa4-42a1-a82a-c8efac159bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac36ce83-c0b8-43ba-82e3-ecb0b65e9ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at HooshvareLab/roberta-fa-zwnj-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at HooshvareLab/roberta-fa-zwnj-base and are newly initialized: ['roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "encoder_config = RobertaConfig.from_pretrained(\"HooshvareLab/roberta-fa-zwnj-base\")\n",
    "decoder_config = RobertaConfig.from_pretrained(\"HooshvareLab/roberta-fa-zwnj-base\")\n",
    "\n",
    "# Allow the decoder to use cross-attention\n",
    "decoder_config.is_decoder = True\n",
    "decoder_config.add_cross_attention = True\n",
    "\n",
    "# Initialize the encoder-decoder model\n",
    "roberta2roberta = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    \"HooshvareLab/roberta-fa-zwnj-base\", \"HooshvareLab/roberta-fa-zwnj-base\",\n",
    "    encoder_config=encoder_config,\n",
    "    decoder_config=decoder_config\n",
    ")\n",
    "\n",
    "roberta2roberta.save_pretrained(\"roberta2roberta_5\")\n",
    "roberta2roberta = EncoderDecoderModel.from_pretrained(\"roberta2roberta_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9bd90ac8-0c5a-4541-a519-8a30cd447191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta2roberta.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "roberta2roberta.config.eos_token_id = tokenizer.sep_token_id\n",
    "roberta2roberta.config.pad_token_id = tokenizer.pad_token_id\n",
    "roberta2roberta.config.vocab_size = roberta2roberta.config.encoder.vocab_size\n",
    "roberta2roberta.config.max_length = 128\n",
    "roberta2roberta.config.min_length = 0\n",
    "roberta2roberta.config.no_repeat_ngram_size = 2\n",
    "roberta2roberta.config.early_stopping = True\n",
    "roberta2roberta.config.length_penalty = 2.0\n",
    "roberta2roberta.config.num_beams = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37772c9e-bc85-4810-9ca5-f3828df4b54f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"roberta2roberta_5\",\n",
       "  \"architectures\": [\n",
       "    \"EncoderDecoderModel\"\n",
       "  ],\n",
       "  \"decoder\": {\n",
       "    \"_attn_implementation_autoset\": true,\n",
       "    \"_name_or_path\": \"HooshvareLab/roberta-fa-zwnj-base\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"architectures\": [\n",
       "      \"RobertaForMaskedLM\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.1,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": null,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"gradient_checkpointing\": false,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.1,\n",
       "    \"hidden_size\": 768,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 3072,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-12,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 514,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"roberta\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"position_embedding_type\": \"absolute\",\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"type_vocab_size\": 1,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 42000\n",
       "  },\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder\": {\n",
       "    \"_attn_implementation_autoset\": true,\n",
       "    \"_name_or_path\": \"HooshvareLab/roberta-fa-zwnj-base\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": [\n",
       "      \"RobertaForMaskedLM\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.1,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 0,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_dropout\": null,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"gradient_checkpointing\": false,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.1,\n",
       "    \"hidden_size\": 768,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 3072,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-12,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 514,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"roberta\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 1,\n",
       "    \"position_embedding_type\": \"absolute\",\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"type_vocab_size\": 1,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 42000\n",
       "  },\n",
       "  \"eos_token_id\": 2,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"length_penalty\": 2.0,\n",
       "  \"max_length\": 128,\n",
       "  \"model_type\": \"encoder-decoder\",\n",
       "  \"no_repeat_ngram_size\": 2,\n",
       "  \"num_beams\": 5,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.47.0\",\n",
       "  \"vocab_size\": 42000\n",
       "}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta2roberta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73154472-9154-4631-8f7b-81f95554ba21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "        predict_with_generate=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        fp16=True,\n",
    "        output_dir=\"roberta2roberta_model_5\",\n",
    "        logging_steps=2,\n",
    "        save_steps=10000,\n",
    "        eval_steps=10000,\n",
    "        num_train_epochs=5,\n",
    "        report_to=\"none\",\n",
    "        warmup_steps=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78061b1-0ae0-4a0f-9c85-9e567ac0b28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1170/2773611530.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='102530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   420/102530 01:01 < 4:09:42, 6.82 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "        model=roberta2roberta,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd4ae1-489f-4cc2-8a37-a7c8117b5700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
